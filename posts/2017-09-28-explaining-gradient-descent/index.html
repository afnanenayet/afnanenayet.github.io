<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="chrome=1"><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><meta name=description content="A personal site"><link href="https://fonts.googleapis.com/css?family=Open+Sans:400|Old+Standard+TT:400" rel=stylesheet type=text/css><link rel=icon type=image/png href=/favicon_16x16.png sizes=16x16><link rel=icon type=image/png href=/favicon_32x32.png sizes=32x32><link rel=icon type=image/png href=/favicon_128x128.png sizes=128x128><link rel=stylesheet href=/style.css><title>Explaining Gradient Descent</title><link rel=canonical href=https://afnan.io/posts/2017-09-28-explaining-gradient-descent/><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body);></script></head><body><section id=nav><h1><a href=/>Afnan Enayet</a></h1><ul><li><a href=/about/>About</a></li><li><a href=/project/>Projects</a></li><li><a href=https://github.com/afnanenayet>Github</a></li></ul></section><section id=content><h1>Explaining Gradient Descent</h1><div id=sub-header>September 2017 Â· 6 minute read</div><div class=entry-content><h2 id=a-classic-statistics-problem>A classic statistics problem</h2><p>In machine learning, problems are often framed as optimization problems. For example,
let us take one of the simplest applications of supervised learning: the linear
regression. It's conceptually an easy problem - given a set of data points,
create a function <span class=math>\( f = ax + b \)</span> that best approximates these points. If you
ever took statistics or have used excel, this is the line of best fit.
Conceptually, this operation doesn't seem too difficult. Note that this is a
supervised learning problem - we need to have a set of observed data to "train"
from. We use this data to create the line of best fit, which we can then subsequently
use to make predictions given new parameters.</p><h2 id=framing-it-as-a-machine-learning-problem>Framing it as a machine learning problem</h2><h3 id=defining-a-linear-regression>Defining a linear regression</h3><p>Let's rewrite the equation <span class=math>\( f(x) = ax + b \)</span> as <span class=math>\( f(x) = a_1 x + a_0 \)</span>. We have
two weights that we need to define, <span class=math>\( a_0 \)</span> and <span class=math>\( a_1 \)</span>, that correspond
to the features <span class=math>\( x_0 \)</span> and <span class=math>\( x_1 \)</span>. <span class=math>\( x_0 = 1 \)</span> and is kind of a
"dummy variable" because we need to fit a linear regression which has the
offset <span class=math>\( a_0 \)</span>, there isn't any actual observation associated with <span class=math>\( x_0 \)</span>
and it has no measured effect on the final line of best fit.</p><p>Our data is defined as a matrix <span class=math>\( X \)</span> where each row of the matrix represents
the readings for the <span class=math>\( i^{th} \)</span> observation. Each row, <span class=math>\( x^{(i)T} \)</span>, is the
set of observed variables for a particular observation, which means it must have
our feature and the observed output. Note that it is transposed because <span class=math>\( x^{(i)} \)</span>
is a vector with the recorded features for that observation. We have another vector
<span class=math>\( Y \)</span> that holds the actual observations for <span class=math>\( X \)</span>, so the <span class=math>\( i^{th} \)</span> element
in <span class=math>\( Y \)</span> corresponds to the <span class=math>\( i^{th} \)</span> row of <span class=math>\( X \)</span>.</p><p>Our objective is to create some function <span class=math>\( f \)</span> in the form <span class=math>\( f(x) = a*0 + a_1 x \)</span>
that best approximates the data in <span class=math>\( X \)</span> and <span class=math>\( Y \)</span>. This means that we need to
pick <span class=math>\( a_0, a_1 \)</span> such that <span class=math>\( f \)</span> best approximates _all* of the data in <span class=math>\( X \)</span>.
So how do we pick the best <span class=math>\( a_0, a_1 \)</span>?</p><h3 id=the-loss-function>The loss function</h3><p>Suppose we randomly guess <span class=math>\( a_0, a_1 \)</span>. We want to know how far off from the actual
data we are, we need a quantitative way to determine how wrong we are. We can measure
the "wrongness" of our function with something called a loss function. A loss function
is a function that provides a measure of your wrongness, and our objective is to
minimize it as best as possible. There are several loss functions you can use, a very
popular loss function is called mean-squared error (MSE).</p><p>We define <span class=math>\( \text{MSE} \)</span> as follows:</p><p><span class=math>\[
\text{MSE} = \frac{1}{n} \sum\_{i = 1}^n (y^{(i)} - f(x^{(i)}))^2
\]</span></p><p>In essence, we are taking every row in <span class=math>\( X \)</span>, making a prediciton with our function
<span class=math>\( f = a_0 + a_1 x \)</span>, taking the difference between the actual <span class=math>\( y \)</span> value and
our prediction <span class=math>\( f(x^{(i)}) \)</span>, then squaring the difference. We do this for every
row, then we divide by <span class=math>\( n \)</span> (the number of data points we have). This gives us
the average squared error in the data set, and lets us quantify how good our
line of best fit is. Of course, we want to minimize our loss function.</p><p>We can find the minimum of a quadratic function by finding the root of the
derivation. Note that it has to be a concave down function, otherwise the
root will give us the maximum.</p><p>Let us define our loss function <span class=math>\( L(a) \)</span> as <span class=math>\( MSE \)</span> and find the minimum.</p><p><span class=math>\[
\begin{aligned}
L(a) &= \frac{1}{n} \sum*{i = 1}^n (y^{(i)} - f(x^{(i)}))^2 \\
L(a) &= \frac{1}{n} \sum*{i = 1}^n (y^{(i)} - (a^T x^{(i)})^2 \\
L'(a) &= \frac{1}{n} _ 2 (y^{(i)} - a^T x^{(i)}) _ -x^{(i)} \\
L'(a) &= -\frac{2}{n} (y^{(i)} - a^T x^{(i)}) x^{(i)} \\
0 &= -\frac{2}{n} (y^{(i)} - a^T x^{(i)}) x^{(i)}
\end{aligned}
\]</span></p><p>We have our derived function, solving for <span class=math>\( a \)</span> will be left as an
exercise to the reader.</p><h2 id=gradient-descent>Gradient Descent</h2><p>With our defined loss function, how do we figure out how to guess <span class=math>\( a \)</span> in
an iterative manner? We could start with some random vector for <span class=math>\( a \)</span> and
then increment the variables a little, trying to lower <span class=math>\( L(a) \)</span> with every
step until we converge on the minimum (so <span class=math>\( L(a) \)</span> cannot be minimized
any further). This is the intuition behind gradient descent, except
gradient descent has a clever way of incrementing the new <span class=math>\( a \)</span> values so
that every time gradient descent iterates, <span class=math>\( L(a) \)</span> is guaranteed to
decrease.</p><p>In gradient descent, take our vector <span class=math>\( a*t \)</span> where <span class=math>\( t \)</span> is our current
iteration. With each iteration of gradient descent, we set <span class=math>\( a*{t+1} \)</span>
equal to some new value as defined below:</p><p><span class=math>\[
\begin{aligned}
a*t &= a*{t-1} - \alpha f(a\_{t-1})
\end{aligned}
\]</span></p><p>Gradient descent allows us to iteratively minimize the loss function - in other
words, this is how we find the value with the least amount of error. Intuitively,
imagine a ball rolling down a hill. The hill is drawn by the loss function, and
we want to reach the bottom. Because we are subtracting by a ratio defined by
the slope of the hill, with a convex function, we should be able to optimize
and find the minimum. If we don't have a strictly concave down function,
there is a chance we will not be able to find the minimum. Additionally,
note the <span class=math>\( \alpha \)</span> term. This is the step size, this is a constant that
we define which will affect how fast our gradient descent mechanism rolls
the ball down the hill. If we keep the step size small, it could take a while
until we reach the bottom of the hill, it might also get stuck in a local minima.
If the step size is too large, it may oscillate around the minimum but never
quite converge.</p><h3 id=optimize-for-big-data-stochastic-gradient-descent>Optimize for big data (stochastic gradient descent)</h3><p>Gradient descent can be an expensive process - imagine our <span class=math>\( n \)</span> is extremely
large (this is the definition of big data). If <span class=math>\( n \)</span> is really big, then
every iteration of gradient descent will be extremely expensive. In practice,
we must balance the accuracy of our models with computation time. A lot of
models that use massive amounts of data mitigate this with a loss function
called stochastic gradient descent.</p><p>The main intuition behind stochastic gradient descent is that the model is
trained and tested on a small subset of the data at a time. This way, you
get a rougher approximation of the optimal value(s), but it is much faster.
Because gradient descent is an approximation itself, the penalty in accuracy
brought on by stochastic gradient descent isn't big enough to outweigh the
performance gains that are brought on by operating on only a batch of the
data at a time.</p><p>If you're using stochastic gradient descent, you'll want to randomly shuffle
the data, and perform each iteration on a randomly shuffled mini-batch.</p></div></section></body></html>